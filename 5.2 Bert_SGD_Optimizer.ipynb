{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28658,"status":"ok","timestamp":1731165484536,"user":{"displayName":"Fahmida ahmed Tonni 212-15-4099","userId":"18059682582730371874"},"user_tz":-360},"id":"PZPZh5lih2OW","outputId":"822a0d66-3954-474d-f56e-f626eb47f145"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n","[Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks/Thesis Project/'\n","/content\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd drive/MyDrive/Colab Notebooks/Thesis Project/\n","\n","!pip install transformers\n","import torch\n","import pandas as pd\n","import numpy as np\n","import torch.nn as nn\n","from transformers import BertModel, BertTokenizer\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold"]},{"cell_type":"code","source":["print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlQotNqRJZbz","executionInfo":{"status":"ok","timestamp":1731165498938,"user_tz":-360,"elapsed":467,"user":{"displayName":"Fahmida ahmed Tonni 212-15-4099","userId":"18059682582730371874"}},"outputId":"19a08a7b-b16a-49bd-c2c8-8e169575c4cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.5.0+cu121\n"]}]},{"cell_type":"code","source":["# Load the data\n","df = pd.read_excel('/content/drive/MyDrive/nlp project dataset/BSMDD_v3_textcleaned - 21K.xlsx')\n","\n","df['label'] = df['label'].map({'Non Depressive': 0, 'Depressive': 1})\n","# Drop rows with any missing values\n","df = df.dropna(subset=['text', 'label'])\n","# drop rows that have identical values in all columns\n","df.drop_duplicates(inplace=True)\n","print(df.info())\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":233},"id":"WCl0k9Gh0JQv","executionInfo":{"status":"ok","timestamp":1731165527745,"user_tz":-360,"elapsed":7941,"user":{"displayName":"Fahmida ahmed Tonni 212-15-4099","userId":"18059682582730371874"}},"outputId":"2c59d165-233b-4cfb-cc8c-4caa3a529465"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 0 entries\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   text    0 non-null      object \n"," 1   label   0 non-null      float64\n","dtypes: float64(1), object(1)\n","memory usage: 0.0+ bytes\n","None\n"]},{"output_type":"execute_result","data":{"text/plain":["Empty DataFrame\n","Columns: [text, label]\n","Index: []"],"text/html":["\n","  <div id=\"df-b8eee5e8-d93b-4031-8982-0f0b350d2a1d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8eee5e8-d93b-4031-8982-0f0b350d2a1d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b8eee5e8-d93b-4031-8982-0f0b350d2a1d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b8eee5e8-d93b-4031-8982-0f0b350d2a1d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","repr_error":"Out of range float values are not JSON compliant: nan"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Check the column names in the DataFrame\n","print(\"Columns in DataFrame:\", df.columns)\n","\n","# If 'word_length' or 'text_length' columns are missing, verify and correct them accordingly\n","if 'word_length' not in df.columns or 'text_length' not in df.columns:\n","    print(\"Please make sure 'word_length' and 'text_length' columns exist in the DataFrame.\")\n","else:\n","    # Proceed with calculations and visualization if columns exist\n","    word_length_mean = df['word_length'].mean()\n","    word_length_median = df['word_length'].median()\n","    word_length_mode = df['word_length'].mode()[0]\n","\n","    text_length_mean = df['text_length'].mean()\n","    text_length_median = df['text_length'].median()\n","    text_length_mode = df['text_length'].mode()[0]\n","\n","    # Calculate skewness\n","    word_length_skewness = df['word_length'].skew()\n","    text_length_skewness = df['text_length'].skew()\n","\n","    # Visualization\n","    plt.figure(figsize=(10, 4))\n","    plt.subplot(1, 2, 1)\n","    sns.histplot(data=df, x='word_length', kde=True)\n","    plt.title('Distribution of Word Length')\n","\n","    plt.subplot(1, 2, 2)\n","    sns.histplot(data=df, x='text_length', kde=True)\n","    plt.title('Distribution of Text Length')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Print results\n","    print('Word Length:')\n","    print('Mean:', word_length_mean)\n","    print('Median:', word_length_median)\n","    print('Mode:', word_length_mode)\n","    print('Skewness:', word_length_skewness)\n","\n","    print('\\nText Length:')\n","    print('Mean:', text_length_mean)\n","    print('Median:', text_length_median)\n","    print('Mode:', text_length_mode)\n","    print('Skewness:', text_length_skewness)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kDpB79YW0JOK","executionInfo":{"status":"ok","timestamp":1731165788615,"user_tz":-360,"elapsed":444,"user":{"displayName":"Fahmida ahmed Tonni 212-15-4099","userId":"18059682582730371874"}},"outputId":"674479de-e508-4079-b681-e211f1efb8ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Columns in DataFrame: Index(['text', 'label'], dtype='object')\n","Please make sure 'word_length' and 'text_length' columns exist in the DataFrame.\n"]}]},{"cell_type":"code","source":["# Calculate the length of each text\n","df['text_length'] = df['text'].str.len()\n","\n","# Calculate max, min, mean, and mode with a check for mode's availability\n","max_length = df['text_length'].max()\n","min_length = df['text_length'].min()\n","mean_length = df['text_length'].mean()\n","\n","# Check if mode exists before accessing it\n","mode_length = df['text_length'].mode()\n","mode_length = mode_length[0] if not mode_length.empty else None\n","\n","# Print the results\n","print(\"Max Length:\", max_length)\n","print(\"Min Length:\", min_length)\n","print(\"Mean Length:\", mean_length)\n","print(\"Mode Length:\", mode_length if mode_length is not None else \"No mode available\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X2_w7onm0JLi","executionInfo":{"status":"ok","timestamp":1731165926359,"user_tz":-360,"elapsed":411,"user":{"displayName":"Fahmida ahmed Tonni 212-15-4099","userId":"18059682582730371874"}},"outputId":"c6a193b5-583b-489d-bdaa-e5c7deafdcb5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Max Length: nan\n","Min Length: nan\n","Mean Length: nan\n","Mode Length: No mode available\n"]}]},{"cell_type":"markdown","source":["### Define Hyperparameter"],"metadata":{"id":"Tep-xoAz9Spx"}},{"cell_type":"code","source":["# Define batch size\n","BATCH_SIZE = 16\n","LEARNING_RATE = 0.1\n","\n","DROPOUT = 0.1\n","\n","# Training loop\n","NUM_EPOCHS = 10\n","\n","# Define number of folds for cross-validation\n","NUM_FOLDS = 5\n","\n","# Momentum -> hyperparameter of Stochastic Gradient Descent (SGD) optimizer\n","MOMENTUM = 0.9\n"],"metadata":{"id":"juxFG72o75lG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the data\n","df = pd.read_excel('/content/drive/MyDrive/nlp project dataset/BSMDD_v3_textcleaned - 21K.xlsx')\n","print(\"Data loaded, shape:\", df.shape)  # Check if data loads correctly\n","\n","# Mapping labels\n","if 'label' in df.columns:\n","    df['label'] = df['label'].map({'Non Depressive': 0, 'Depressive': 1})\n","    print(\"Label mapping done.\")\n","else:\n","    print(\"Column 'label' not found in DataFrame.\")\n","\n","# Drop rows with any missing values in 'text' and 'label'\n","df = df.dropna(subset=['text', 'label'])\n","print(\"After dropping missing values, shape:\", df.shape)\n","\n","# Drop duplicate rows\n","df.drop_duplicates(inplace=True)\n","print(\"After dropping duplicates, shape:\", df.shape)\n","\n","# Keep only 'text' and 'label' columns\n","columns_to_drop = [col for col in df.columns if col not in ['text', 'label']]\n","df.drop(columns=columns_to_drop, inplace=True)\n","print(\"After dropping unnecessary columns, shape:\", df.shape)\n","\n","# Check DataFrame info and label counts\n","print(df.info())\n","label_counts = df['label'].value_counts()\n","print(\"Label Details:\")\n","print(label_counts)\n","\n","# Display a sample if DataFrame is not empty\n","if not df.empty:\n","    print(df.sample(n=10))\n","else:\n","    print(\"DataFrame is empty after processing.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"erIPs2Khoevg","executionInfo":{"status":"ok","timestamp":1731166084677,"user_tz":-360,"elapsed":3579,"user":{"displayName":"Fahmida ahmed Tonni 212-15-4099","userId":"18059682582730371874"}},"outputId":"82f574a1-7ce1-49e9-adec-4fdbb5937e31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data loaded, shape: (21910, 2)\n","Label mapping done.\n","After dropping missing values, shape: (0, 2)\n","After dropping duplicates, shape: (0, 2)\n","After dropping unnecessary columns, shape: (0, 2)\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 0 entries\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   text    0 non-null      object \n"," 1   label   0 non-null      float64\n","dtypes: float64(1), object(1)\n","memory usage: 0.0+ bytes\n","None\n","Label Details:\n","Series([], Name: count, dtype: int64)\n","DataFrame is empty after processing.\n"]}]},{"cell_type":"code","source":["# Check the counts of each label\n","label_counts = df['label'].value_counts()\n","print(\"Label counts before sampling:\", label_counts)\n","\n","# Determine the minimum count available for each label\n","min_count = min(label_counts.get(0, 0), label_counts.get(1, 0))\n","\n","# Sample only up to the available number of instances for each label\n","df_label_0 = df[df['label'] == 0].sample(n=min_count, random_state=42)\n","df_label_1 = df[df['label'] == 1].sample(n=min_count, random_state=42)\n","\n","# Concatenate the sampled dataframes\n","df = pd.concat([df_label_0, df_label_1], ignore_index=True)\n","\n","# Display info and label distribution\n","print(df.info())\n","label_counts = df['label'].value_counts()\n","print(\"Label Details:\")\n","print(label_counts)\n","\n","# Display random samples\n","if not df.empty:\n","    print(df.sample(n=10))\n","else:\n","    print(\"DataFrame is empty after sampling.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brJpM3Cap_ze","executionInfo":{"status":"ok","timestamp":1731166137369,"user_tz":-360,"elapsed":4,"user":{"displayName":"Fahmida ahmed Tonni 212-15-4099","userId":"18059682582730371874"}},"outputId":"fa2d0bf3-cf0c-4e4a-e4aa-951c6b0abfa6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Label counts before sampling: Series([], Name: count, dtype: int64)\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 0 entries\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   text    0 non-null      object \n"," 1   label   0 non-null      float64\n","dtypes: float64(1), object(1)\n","memory usage: 124.0+ bytes\n","None\n","Label Details:\n","Series([], Name: count, dtype: int64)\n","DataFrame is empty after sampling.\n"]}]},{"cell_type":"code","source":["X = df['text']\n","y = df['label']\n","print(X.info())\n","print(y.info())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mTmJIuExpeY3","executionInfo":{"status":"ok","timestamp":1731166142998,"user_tz":-360,"elapsed":513,"user":{"displayName":"Fahmida ahmed Tonni 212-15-4099","userId":"18059682582730371874"}},"outputId":"7529b83d-d9a3-452b-c61d-44ff0f842ce6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.series.Series'>\n","RangeIndex: 0 entries\n","Series name: text\n","Non-Null Count  Dtype \n","--------------  ----- \n","0 non-null      object\n","dtypes: object(1)\n","memory usage: 124.0+ bytes\n","None\n","<class 'pandas.core.series.Series'>\n","RangeIndex: 0 entries\n","Series name: label\n","Non-Null Count  Dtype  \n","--------------  -----  \n","0 non-null      float64\n","dtypes: float64(1)\n","memory usage: 124.0 bytes\n","None\n"]}]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"BekcQiBrJVY1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define the BERT model architecture"],"metadata":{"id":"2seNRUyUTH-s"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import StratifiedKFold\n","from transformers import BertTokenizer, BertModel\n","import matplotlib.pyplot as plt\n","\n","# Define the BERT classifier model\n","class BERTClassifier(nn.Module):\n","    def __init__(self, bert_model, hidden_dim, num_classes):\n","        super(BERTClassifier, self).__init__()\n","        self.bert_model = bert_model\n","        self.fc = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.bert_model(input_ids, attention_mask)[1]  # Use the [CLS] token representation\n","        logits = self.fc(output)\n","        return logits\n","\n","\n","# Set device\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load and verify data for X and y\n","try:\n","    # Replace with actual data loading code\n","    # For example:\n","    # df = pd.read_csv('path_to_your_dataset.csv')\n","    # X = df['text_column_name']\n","    # y = df['label_column_name']\n","\n","    # Check if X and y are properly loaded and contain data\n","    if 'X' in globals() and 'y' in globals() and len(X) > 0 and len(y) > 0:\n","        # Convert X to a list of strings if it's not already\n","        X = list(X)\n","\n","        # Load the BERT tokenizer and encode the text data\n","        tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","        X_encodings = tokenizer(X, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n","\n","        # Convert labels to tensor\n","        y_tensor = torch.tensor(y.values)\n","    else:\n","        print(\"Error: X and/or y are not defined or are empty. Please ensure the data is correctly loaded.\")\n","        raise ValueError(\"X or y is empty\")\n","\n","except Exception as e:\n","    print(f\"An error occurred during data loading or tokenization: {e}\")\n","    raise\n","\n","# Initialize the StratifiedKFold\n","NUM_FOLDS = 5  # Define number of folds\n","BATCH_SIZE = 16  # Set batch size\n","LEARNING_RATE = 1e-3  # Set learning rate\n","MOMENTUM = 0.9  # Set momentum\n","NUM_EPOCHS = 3  # Set number of epochs\n","\n","skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n","\n","# Perform cross-validation\n","for fold, (train_index, val_index) in enumerate(skf.split(X_encodings['input_ids'], y_tensor), 1):\n","    print(f\"Processing Fold: {fold}\")\n","\n","    # Split data into train and validation sets\n","    X_train_fold = {key: X_encodings[key][train_index] for key in X_encodings}\n","    X_val_fold = {key: X_encodings[key][val_index] for key in X_encodings}\n","    y_train_fold = y_tensor[train_index]\n","    y_val_fold = y_tensor[val_index]\n","\n","    # Create PyTorch datasets\n","    train_dataset = TensorDataset(X_train_fold['input_ids'], X_train_fold['attention_mask'], y_train_fold)\n","    val_dataset = TensorDataset(X_val_fold['input_ids'], X_val_fold['attention_mask'], y_val_fold)\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n","\n","    # Initialize the BERT model\n","    bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n","    hidden_dim = bert_model.config.hidden_size\n","    num_classes = 2  # Adjust this as per your actual number of classes\n","    model = BERTClassifier(bert_model, hidden_dim, num_classes)\n","    model.to(DEVICE)\n","\n","    # Define optimizer and loss function\n","    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    best_accuracy = 0.0\n","    best_model_path = f'best_model_fold{fold}.pth'\n","\n","    # Define lists to store train and validation metrics per epoch\n","    train_losses_per_epoch = []\n","    train_accuracies_per_epoch = []\n","    val_losses_per_epoch = []\n","    val_accuracies_per_epoch = []\n","\n","    for epoch in range(NUM_EPOCHS):\n","        model.train()\n","        train_loss = 0.0\n","        train_correct = 0\n","        train_total = 0\n","\n","        for batch in train_loader:\n","            input_ids, attention_mask, labels = batch\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","            labels = labels.to(DEVICE)\n","\n","            optimizer.zero_grad()\n","            logits = model(input_ids, attention_mask)\n","            _, predicted = torch.max(logits, 1)\n","\n","            loss = criterion(logits, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item() * input_ids.size(0)\n","            train_total += labels.size(0)\n","            train_correct += (predicted == labels).sum().item()\n","\n","        train_accuracy = 100 * train_correct / train_total\n","\n","        model.eval()\n","        val_loss = 0.0\n","        val_correct = 0\n","        val_total = 0\n","\n","        with torch.no_grad():\n","            for batch in val_loader:\n","                input_ids, attention_mask, labels = batch\n","                input_ids = input_ids.to(DEVICE)\n","                attention_mask = attention_mask.to(DEVICE)\n","                labels = labels.to(DEVICE)\n","\n","                logits = model(input_ids, attention_mask)\n","                _, predicted = torch.max(logits, 1)\n","\n","                loss = criterion(logits, labels)\n","\n","                val_loss += loss.item() * input_ids.size(0)\n","                val_total += labels.size(0)\n","                val_correct += (predicted == labels).sum().item()\n","\n","        val_accuracy = 100 * val_correct / val_total\n","\n","        train_losses_per_epoch.append(train_loss / train_total)\n","        train_accuracies_per_epoch.append(train_accuracy)\n","        val_losses_per_epoch.append(val_loss / val_total)\n","        val_accuracies_per_epoch.append(val_accuracy)\n","\n","        print('Epoch: {}/{} | Train Loss: {:.4f} | Train Accuracy: {:.2f}% | Val Loss: {:.4f} | Val Accuracy: {:.2f}%'.format(\n","            epoch + 1, NUM_EPOCHS, train_loss / train_total, train_accuracy, val_loss / val_total, val_accuracy))\n","\n","        # Save the best model based on validation accuracy\n","        if val_accuracy > best_accuracy:\n","            best_accuracy = val_accuracy\n","            torch.save(model, best_model_path)\n","            print(\"Best model saved!\")\n","\n","    print(\"Training completed for Fold:\", fold)\n","\n","    # Load the best model for evaluation if needed\n","    best_model = torch.load(best_model_path)\n","    best_model.to(DEVICE)\n","    best_model.eval()\n","\n","    # You can proceed with further evaluation or inference here\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"F6LX0EyjfxD9","outputId":"bc8fbd92-7aab-45a9-fb24-1200bfd6e08d","executionInfo":{"status":"error","timestamp":1731166422269,"user_tz":-360,"elapsed":673,"user":{"displayName":"Fahmida ahmed Tonni 212-15-4099","userId":"18059682582730371874"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error: X and/or y are not defined or are empty. Please ensure the data is correctly loaded.\n","An error occurred during data loading or tokenization: X or y is empty\n"]},{"output_type":"error","ename":"ValueError","evalue":"X or y is empty","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-1610ac8c3381>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error: X and/or y are not defined or are empty. Please ensure the data is correctly loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X or y is empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: X or y is empty"]}]},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# Load the test data\n","test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=512)\n","test_dataset = TensorDataset(torch.tensor(test_encodings['input_ids']),\n","                             torch.tensor(test_encodings['attention_mask']),\n","                             torch.tensor(y_test.values))\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n","\n","# Load the best model for evaluation\n","best_model = torch.load(best_model_path)\n","best_model.to(DEVICE)\n","best_model.eval()\n","\n","test_loss = 0.0\n","test_correct = 0\n","test_total = 0\n","predictions = []\n","\n","with torch.no_grad():\n","    for batch in test_loader:\n","        input_ids, attention_mask, labels = batch\n","        input_ids = input_ids.to(DEVICE)\n","        attention_mask = attention_mask.to(DEVICE)\n","        labels = labels.to(DEVICE)\n","\n","        logits = best_model(input_ids, attention_mask)\n","        _, predicted = torch.max(logits, 1)\n","\n","        loss = criterion(logits, labels)\n","\n","        test_loss += loss.item() * input_ids.size(0)\n","        test_total += labels.size(0)\n","        test_correct += (predicted == labels).sum().item()\n","\n","        predictions.extend(predicted.cpu().numpy())\n","\n","test_accuracy = 100 * test_correct / test_total\n","test_loss = test_loss / test_total\n","\n","# Calculate precision, recall, and F1 score\n","precision = precision_score(y_test.values, predictions)\n","recall = recall_score(y_test.values, predictions)\n","f1 = f1_score(y_test.values, predictions)\n","\n","print('Test Loss: {:.4f} | Test Accuracy: {:.2f}%'.format(test_loss, test_accuracy))\n","print('Precision: {:.4f} | Recall: {:.4f} | F1 Score: {:.4f}'.format(precision, recall, f1))\n"],"metadata":{"id":"0uYO1UFJfxBQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the validation and test accuracy\n","plt.plot(range(1, NUM_EPOCHS + 1), val_accuracies_per_epoch, label='Validation Accuracy')\n","plt.axhline(y=test_accuracy, color='r', linestyle='--', label='Test Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title('Validation and Test Accuracy')\n","plt.legend()\n","plt.show()\n","\n","# Plot the validation and test loss\n","plt.plot(range(1, NUM_EPOCHS + 1), val_losses_per_epoch, label='Validation Loss')\n","plt.axhline(y=test_loss, color='r', linestyle='--', label='Test Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Validation and Test Loss')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"7-u1POlGfw-s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EdwPEKudfw8d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"quIdted0fw5s"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289,"referenced_widgets":["98351763025e4bfcab9cdcdd5e58b003","c7e66402a94d4104a7318f77c8f77d96","b8a9f2b21b784d4c8ace83f6f20ae813","8d716ac39f8747cca4b9172d4058ae40","314ae781516a434fa3e20630afe676c8","4b72d083672e4431a4d8427da4fb1757","6f068bf59d5d4f34b0031971a81cf2b7","d579235013284c679fa09bdd15332ba4","b44e49dc36ab4c0f9b1a7965b3d37e77","409a5c7cd7dc4d228d5de8da11b546da","a2e5d32460ef4517bc8d965593e3999b","c908c84ac6a04304b01c45d2731d751a","896edcfa135e4b688a4a556141761d20","960efdaf19d44b34bdfc1f491480c9cc","524c27d5e0d84eb3a71280e9044d8276","e5b5102d12c1400387d71e32332676e9","5300f01ba23f455db32eada0b6f9a8bd","8ff2f07abe62441cab183cb804f99fe3","11207315c0dc48c4afe3b680b51578a8","0bbdb7af03fb415fa01e5b621209b60f","4544319004434ce084672c24407c358a","80d83f2ae8ed4d02af0f47a8d6222f47","094affce43c1468583ad2db010528d18","cb47ebcfc0c9410fb2a3e9b23ef2e3d1","c5d3a1f921364c9b882f3cd22ff949dc","e5a192af4e6445a485e9b2dd3647759a","29b7868635d5408bb807c247f31a13dd","687475143f01493182e917a88ba3d857","bbae3ed57b9c4693b2467e17b62dcd2f","a6ad9dd7e0b545e1b8104b318a255d0a","399879f292f24e828ce5a6265db47a71","dda21360cc6642a7a50701275ae18e97","254e736fc7f7472ab0bfd4fb84c846fa"]},"executionInfo":{"elapsed":162796,"status":"ok","timestamp":1687020947247,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"},"user_tz":-360},"id":"lRjZuXCFh6dy","outputId":"47cd7038-ab0e-4214-dad5-c71bd706ded3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98351763025e4bfcab9cdcdd5e58b003"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c908c84ac6a04304b01c45d2731d751a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"094affce43c1468583ad2db010528d18"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-9705a8b77c1d>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(y_train_fold))\n","<ipython-input-9-9705a8b77c1d>:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  torch.tensor(y_val_fold))\n"]},{"output_type":"stream","name":"stdout","text":["Processing Fold: 2\n","Processing Fold: 3\n","Processing Fold: 4\n","Processing Fold: 5\n"]}],"source":["# Define the BERT model architecture\n","class BERTClassifier(nn.Module):\n","    def __init__(self, bert_model, hidden_dim, num_classes):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert_model\n","        self.dropout = nn.Dropout(DROPOUT)\n","        self.fc = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = output['pooler_output']\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.fc(pooled_output)\n","        return torch.sigmoid(logits)\n","\n","\n","# Set device\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Load the BERT tokenizer and encode the text data\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","X_encodings = tokenizer(list(X), truncation=True, padding=True, max_length=512)\n","\n","# Convert labels to tensor\n","y_tensor = torch.tensor(y.values)\n","\n","# Initialize the StratifiedKFold\n","skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n","\n","# Perform cross-validation\n","for fold, (train_index, val_index) in enumerate(skf.split(X_encodings['input_ids'], y_tensor), 1):\n","    print(f\"Processing Fold: {fold}\")\n","\n","    # Convert X_encodings to a list of tuples\n","    X_encodings_list = list(X_encodings.items())\n","\n","    # Split data into train and validation sets\n","    X_train_fold = {key: [value[i] for i in train_index] for key, value in X_encodings_list}\n","    X_val_fold = {key: [value[i] for i in val_index] for key, value in X_encodings_list}\n","    y_train_fold = y_tensor[train_index]\n","    y_val_fold = y_tensor[val_index]\n","\n","\n","    # Create PyTorch datasets\n","    train_dataset = TensorDataset(torch.tensor(X_train_fold['input_ids']),\n","                                  torch.tensor(X_train_fold['attention_mask']),\n","                                  torch.tensor(y_train_fold))\n","    val_dataset = TensorDataset(torch.tensor(X_val_fold['input_ids']),\n","                                torch.tensor(X_val_fold['attention_mask']),\n","                                torch.tensor(y_val_fold))\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n"]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n"],"metadata":{"id":"_p7TNgcbJ37z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Define the BERT classifier model\n","class BERTClassifier(nn.Module):\n","    def __init__(self, bert_model, hidden_dim, num_classes):\n","        super(BERTClassifier, self).__init__()\n","        self.bert_model = bert_model\n","        self.fc = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.bert_model(input_ids, attention_mask)[1]  # Use the [CLS] token representation\n","        logits = self.fc(output)\n","        return logits\n","\n","# Set the device\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the BERT model\n","bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n","\n","hidden_dim = bert_model.config.hidden_size\n","num_classes = 2\n","\n","model = BERTClassifier(bert_model, hidden_dim, num_classes).to(DEVICE)\n","\n","\n","\n","# Freeze BERT layer\n","for param in model.bert_model.parameters():\n","    param.requires_grad = False\n","\n","# Unfreeze output layer\n","for param in model.fc.parameters():\n","    param.requires_grad = True\n","\n","\n","# Define the optimizer and loss function\n","optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE, momentum=MOMENTUM)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# Define the optimizer and loss function\n","# optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n","# criterion = nn.CrossEntropyLoss()\n","\n","best_accuracy = 0.0\n","\n","# Define lists to store metrics for each fold\n","fold_train_losses = []\n","fold_train_accuracies = []\n","fold_val_losses = []\n","fold_val_accuracies = []\n","fold_val_predictions = []\n","fold_val_labels = []\n","\n","# Define lists to store train and validation metrics per epoch\n","train_losses_per_epoch = []\n","train_accuracies_per_epoch = []\n","val_losses_per_epoch = []\n","val_accuracies_per_epoch = []\n","\n","for epoch in range(NUM_EPOCHS):\n","    model.train()\n","    train_loss = 0.0\n","    train_correct = 0\n","    train_total = 0\n","\n","    for batch in train_loader:\n","      input_ids, attention_mask, labels = batch\n","      input_ids = input_ids.to(DEVICE)\n","      attention_mask = attention_mask.to(DEVICE)\n","      labels = labels.to(DEVICE)\n","\n","      optimizer.zero_grad()\n","\n","      logits = model(input_ids, attention_mask)\n","      _, predicted = torch.max(logits, 1)\n","\n","      loss = criterion(logits, labels)\n","      loss.backward()\n","      optimizer.step()\n","\n","      train_loss += loss.item() * input_ids.size(0)\n","      train_total += labels.size(0)\n","      train_correct += (predicted == labels).sum().item()\n","\n","    train_accuracy = 100 * train_correct / train_total\n","\n","    model.eval()\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","\n","    with torch.no_grad():\n","        for batch in val_loader:\n","          input_ids, attention_mask, labels = batch\n","          input_ids = input_ids.to(DEVICE)\n","          attention_mask = attention_mask.to(DEVICE)\n","          labels = labels.to(DEVICE)\n","\n","          logits = model(input_ids, attention_mask)\n","          _, predicted = torch.max(logits, 1)\n","\n","          loss = criterion(logits, labels)\n","\n","          val_loss += loss.item() * input_ids.size(0)\n","          val_total += labels.size(0)\n","          val_correct += (predicted == labels).sum().item()\n","\n","          fold_val_predictions.extend(predicted.cpu().numpy())\n","          fold_val_labels.extend(labels.cpu().numpy())\n","\n","    val_accuracy = 100 * val_correct / val_total\n","\n","    fold_train_losses.append(train_loss / train_total)\n","    fold_train_accuracies.append(train_accuracy)\n","    fold_val_losses.append(val_loss / val_total)\n","    fold_val_accuracies.append(val_accuracy)\n","\n","    train_losses_per_epoch.append(train_loss / train_total)\n","    train_accuracies_per_epoch.append(train_accuracy)\n","    val_losses_per_epoch.append(val_loss / val_total)\n","    val_accuracies_per_epoch.append(val_accuracy)\n","\n","    print('Epoch: {}/{} | Train Loss: {:.4f} | Train Accuracy: {:.2f}% | Val Loss: {:.4f} | Val Accuracy: {:.2f}%'.format(\n","        epoch + 1, NUM_EPOCHS, train_loss / train_total, train_accuracy, val_loss / val_total, val_accuracy))\n","\n","    if val_accuracy > best_accuracy:\n","        best_accuracy = val_accuracy\n","        torch.save(model.state_dict(), 'best_model.pth')\n","\n","\n","# Calculate performance metrics\n","threshold = 0.5  # Adjust the threshold based on your task and preferences\n","fold_val_predictions_binary = [1 if pred >= threshold else 0 for pred in fold_val_predictions]\n","fold_val_labels_binary = [1 if label >= threshold else 0 for label in fold_val_labels]\n","\n","average_accuracy = accuracy_score(fold_val_labels_binary, fold_val_predictions_binary)\n","average_precision = precision_score(fold_val_labels_binary, fold_val_predictions_binary)\n","average_recall = recall_score(fold_val_labels_binary, fold_val_predictions_binary)\n","average_f1_score = f1_score(fold_val_labels_binary, fold_val_predictions_binary)\n","\n","# Print average metrics across folds\n","print('Average Metrics Across Folds:')\n","print('Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f} | F1 Score: {:.4f}'.format(\n","    average_accuracy, average_precision, average_recall, average_f1_score))\n","\n","# Plotting the train and validation accuracy and loss graphs\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(train_losses_per_epoch, label='Train Loss')\n","plt.plot(val_losses_per_epoch, label='Val Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(train_accuracies_per_epoch, label='Train Accuracy')\n","plt.plot(val_accuracies_per_epoch, label='Val Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"cEJH6YcuTpMN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vZ71C9XaTpJM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AZHFIaYhTpGc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4IBF3kriTpDl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Define the BERT classifier model\n","class BERTClassifier(nn.Module):\n","    def __init__(self, bert_model, hidden_dim, num_classes):\n","        super(BERTClassifier, self).__init__()\n","        self.bert_model = bert_model\n","        self.fc = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.bert_model(input_ids, attention_mask)[1]  # Use the [CLS] token representation\n","        logits = self.fc(output)\n","        return logits\n","\n","# Set the device\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the BERT model\n","bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n","\n","\n","hidden_dim = bert_model.config.hidden_size\n","num_classes = 2\n","#bert_model = torch.compile(bert_model)\n","model = BERTClassifier(bert_model, hidden_dim, num_classes).to(DEVICE)\n","model = torch.compile(model)\n","\n","# Define the optimizer and loss function\n","optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n","criterion = nn.CrossEntropyLoss()\n","\n","best_accuracy = 0.0\n","\n","# Freeze BERT layer\n","for param in model.bert_model.parameters():\n","    param.requires_grad = False\n","\n","# Unfreeze output layer\n","for param in model.fc.parameters():\n","    param.requires_grad = True\n","\n","# Define lists to store metrics for each fold\n","fold_train_losses = []\n","fold_train_accuracies = []\n","fold_val_losses = []\n","fold_val_accuracies = []\n","fold_val_predictions = []\n","fold_val_labels = []\n","\n","# Define lists to store train and validation metrics per epoch\n","train_losses_per_epoch = []\n","train_accuracies_per_epoch = []\n","val_losses_per_epoch = []\n","val_accuracies_per_epoch = []\n","\n","for epoch in range(NUM_EPOCHS):\n","    model.train()\n","    train_loss = 0.0\n","    train_correct = 0\n","    train_total = 0\n","\n","    for batch in train_loader:\n","      input_ids, attention_mask, labels = batch\n","      input_ids = input_ids.to(DEVICE)\n","      attention_mask = attention_mask.to(DEVICE)\n","      labels = labels.to(DEVICE)\n","\n","      optimizer.zero_grad()\n","\n","      logits = model(input_ids, attention_mask)\n","      _, predicted = torch.max(logits, 1)\n","\n","      loss = criterion(logits, labels)\n","      loss.backward()\n","      optimizer.step()\n","\n","      train_loss += loss.item() * input_ids.size(0)\n","      train_total += labels.size(0)\n","      train_correct += (predicted == labels).sum().item()\n","\n","    train_accuracy = 100 * train_correct / train_total\n","\n","    model.eval()\n","    val_loss = 0.0\n","    val_correct = 0\n","    val_total = 0\n","\n","    with torch.no_grad():\n","        for batch in val_loader:\n","          input_ids, attention_mask, labels = batch\n","          input_ids = input_ids.to(DEVICE)\n","          attention_mask = attention_mask.to(DEVICE)\n","          labels = labels.to(DEVICE)\n","\n","          logits = model(input_ids, attention_mask)\n","          _, predicted = torch.max(logits, 1)\n","\n","          loss = criterion(logits, labels)\n","\n","          val_loss += loss.item() * input_ids.size(0)\n","          val_total += labels.size(0)\n","          val_correct += (predicted == labels).sum().item()\n","\n","          fold_val_predictions.extend(predicted.cpu().numpy())\n","          fold_val_labels.extend(labels.cpu().numpy())\n","\n","    val_accuracy = 100 * val_correct / val_total\n","\n","    fold_train_losses.append(train_loss / train_total)\n","    fold_train_accuracies.append(train_accuracy)\n","    fold_val_losses.append(val_loss / val_total)\n","    fold_val_accuracies.append(val_accuracy)\n","\n","    train_losses_per_epoch.append(train_loss / train_total)\n","    train_accuracies_per_epoch.append(train_accuracy)\n","    val_losses_per_epoch.append(val_loss / val_total)\n","    val_accuracies_per_epoch.append(val_accuracy)\n","\n","    print('Epoch: {}/{} | Train Loss: {:.4f} | Train Accuracy: {:.2f}% | Val Loss: {:.4f} | Val Accuracy: {:.2f}%'.format(\n","        epoch + 1, NUM_EPOCHS, train_loss / train_total, train_accuracy, val_loss / val_total, val_accuracy))\n","\n","    if val_accuracy > best_accuracy:\n","        best_accuracy = val_accuracy\n","        torch.save(model.state_dict(), 'best_model.pth')\n","\n","# Calculate performance metrics\n","average_accuracy = accuracy_score(fold_val_labels, fold_val_predictions)\n","average_precision = precision_score(fold_val_labels, fold_val_predictions)\n","average_recall = recall_score(fold_val_labels, fold_val_predictions)\n","average_f1_score = f1_score(fold_val_labels, fold_val_predictions)\n","\n","# Print average metrics across folds\n","print('Average Metrics Across Folds:')\n","print('Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f} | F1 Score: {:.4f}'.format(\n","    average_accuracy, average_precision, average_recall, average_f1_score))\n","\n","# Plotting the train and validation accuracy and loss graphs\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(train_losses_per_epoch, label='Train Loss')\n","plt.plot(val_losses_per_epoch, label='Val Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(train_accuracies_per_epoch, label='Train Accuracy')\n","plt.plot(val_accuracies_per_epoch, label='Val Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295,"referenced_widgets":["57a1f4ef9ced4a52bca0a34d876d38a0","3cbe220f906340b0a969828e537770a6","92b9f956e7664c52bc79826c7aae4a29","7e6462bd0a974396adf7c650c6ceb870","07649f5e2a804c2fa71408736484dc45","ba2478699f574349a9f66dcba210eecb","1166a54d74ea4fea8dd0f4199ac2d0af","e23808f1bf4c4558a289e0ce9225ee5c","aa9868d2e8cf4fc5bf670be44913806a","fa21852b505d4481a6a67300da47a275","3b90a4547c8249a4ac252f9bad409ca5"]},"id":"j7Dk24g4oDiX","outputId":"1f4a8679-1186-443f-cd99-fa6dbfb71b3f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57a1f4ef9ced4a52bca0a34d876d38a0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[2023-06-17 16:56:13,583] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1/40 | Train Loss: 0.5583 | Train Accuracy: 71.62% | Val Loss: 0.4268 | Val Accuracy: 81.09%\n","Epoch: 2/40 | Train Loss: 0.4970 | Train Accuracy: 76.56% | Val Loss: 0.4249 | Val Accuracy: 80.73%\n","Epoch: 3/40 | Train Loss: 0.4867 | Train Accuracy: 77.50% | Val Loss: 0.4611 | Val Accuracy: 80.86%\n","Epoch: 4/40 | Train Loss: 0.4704 | Train Accuracy: 78.16% | Val Loss: 0.3855 | Val Accuracy: 83.00%\n","Epoch: 5/40 | Train Loss: 0.4749 | Train Accuracy: 78.38% | Val Loss: 0.4354 | Val Accuracy: 82.12%\n","Epoch: 6/40 | Train Loss: 0.4620 | Train Accuracy: 78.83% | Val Loss: 0.3740 | Val Accuracy: 83.48%\n","Epoch: 7/40 | Train Loss: 0.4610 | Train Accuracy: 78.91% | Val Loss: 0.3909 | Val Accuracy: 82.77%\n","Epoch: 8/40 | Train Loss: 0.4582 | Train Accuracy: 79.43% | Val Loss: 0.3708 | Val Accuracy: 83.79%\n","Epoch: 9/40 | Train Loss: 0.4542 | Train Accuracy: 79.27% | Val Loss: 0.3892 | Val Accuracy: 82.61%\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wJLkPX-AoDe_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bBd5j3oDk_F5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import StratifiedKFold, GridSearchCV\n","from transformers import BertTokenizer, BertModel\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Load the data\n","df = pd.read_excel('0. All Datasets.xlsx')\n","df['label'] = df['label'].map({'Non Depressive': 0, 'Depressive': 1})\n","df = df.dropna(subset=['text', 'label'])\n","df.drop_duplicates(inplace=True)\n","columns_to_drop = [col for col in df.columns if col not in ['text', 'label']]\n","df.drop(columns=columns_to_drop, inplace=True)\n","\n","label_counts = df['label'].value_counts()\n","print(\"Label Details:\")\n","print(label_counts)\n","\n","# Sample 14,000 instances for each label\n","df_label_0 = df[df['label'] == 0].sample(n=14000, random_state=42)\n","df_label_1 = df[df['label'] == 1].sample(n=14000, random_state=42)\n","\n","# Concatenate the sampled dataframes\n","df = pd.concat([df_label_0, df_label_1], ignore_index=True)\n","\n","X = df['text']\n","y = df['label']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CosnN8h0k_Cx","executionInfo":{"status":"ok","timestamp":1687076654674,"user_tz":-360,"elapsed":7559,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"1dff7fba-4f0a-4968-f955-b24df34daeea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Label Details:\n","0    16719\n","1    14976\n","Name: label, dtype: int64\n"]}]},{"cell_type":"code","source":["# Define the BERT classifier model\n","class BERTClassifierWrapper(nn.Module):\n","    def __init__(self, bert_model, hidden_dim, num_classes):\n","        super(BERTClassifierWrapper, self).__init__()\n","        self.bert_model = bert_model\n","        self.fc = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.bert_model(input_ids, attention_mask)[1]  # Use the [CLS] token representation\n","        logits = self.fc(output)\n","        return logits\n","\n","    def fit(self, input_ids, attention_mask, labels, criterion, optimizer, num_epochs, batch_size):\n","        dataset = TensorDataset(input_ids, attention_mask, labels)\n","        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","        self.train()\n","        for epoch in range(num_epochs):\n","            running_loss = 0.0\n","            for i, batch in enumerate(data_loader):\n","                input_ids_batch, attention_mask_batch, labels_batch = batch\n","                input_ids_batch = input_ids_batch.to(DEVICE)\n","                attention_mask_batch = attention_mask_batch.to(DEVICE)\n","                labels_batch = labels_batch.to(DEVICE)\n","\n","                optimizer.zero_grad()\n","\n","                outputs = self(input_ids_batch, attention_mask_batch)\n","                loss = criterion(outputs, labels_batch)\n","\n","                loss.backward()\n","                optimizer.step()\n","\n","                running_loss += loss.item()\n","\n","            print(f\"Epoch {epoch+1}/{num_epochs} Loss: {running_loss / len(data_loader)}\")\n","\n","    def predict(self, input_ids, attention_mask):\n","        dataset = TensorDataset(input_ids, attention_mask)\n","        data_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n","\n","        self.eval()\n","        predictions = []\n","        with torch.no_grad():\n","            for batch in data_loader:\n","                input_ids_batch, attention_mask_batch = batch\n","                input_ids_batch = input_ids_batch.to(DEVICE)\n","                attention_mask_batch = attention_mask_batch.to(DEVICE)\n","\n","                outputs = self(input_ids_batch, attention_mask_batch)\n","                _, predicted_labels = torch.max(outputs, dim=1)\n","\n","                predictions.extend(predicted_labels.cpu().numpy())\n","\n","        return predictions\n","\n","# Load the BERT tokenizer and encode the text data\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","X_encodings = tokenizer(list(X), truncation=True, padding=True, max_length=512)\n","\n","# Convert labels to tensor\n","y_tensor = torch.tensor(y.values)\n","\n","# Set device\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# Define hyperparameters and their possible values for grid search\n","parameters = {\n","    'num_epochs': [5, 10],\n","    'batch_size': [32, 64],\n","    'learning_rate': [0.001, 0.01],\n","    'momentum': [0.9, 0.95],\n","    'dropout': [0.1, 0.2],\n","}\n","\n","# Initialize the BERT model\n","bert_model = BertModel.from_pretrained('bert-base-multilingual-cased')\n","hidden_dim = bert_model.config.hidden_size\n","num_classes = 2\n","\n","# Create the BERT classifier model\n","model = BERTClassifierWrapper(bert_model, hidden_dim, num_classes).to(DEVICE)\n","\n","# Define the optimizer and loss function\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Define the grid search\n","grid_search = GridSearchCV(model, parameters, cv=5, scoring='accuracy')\n","\n","# Run grid search\n","grid_search.fit(X_encodings['input_ids'], X_encodings['attention_mask'], y_tensor, criterion, optimizer)\n","\n","# Print the best parameters and score\n","print(\"Best Parameters: \", grid_search.best_params_)\n","print(\"Best Score: \", grid_search.best_score_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QEFFs_cYk-_6","executionInfo":{"status":"error","timestamp":1687077320364,"user_tz":-360,"elapsed":151686,"user":{"displayName":"Ahmadul Karim Chowdhury","userId":"09340342089296209091"}},"outputId":"087c5631-f389-4ec5-e106-073fd664970f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-6f8a1441cfb4>\u001b[0m in \u001b[0;36m<cell line: 92>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m# Run grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# Print the best parameters and score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: BaseSearchCV.fit() takes from 2 to 3 positional arguments but 6 were given"]}]},{"cell_type":"code","source":[],"metadata":{"id":"65Wt5dEck-4Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YM_zR66fk-1Z"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1PdjHcPtvADoN-vrPUqdfYrOSWiQd0FTN","timestamp":1686846778720}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"98351763025e4bfcab9cdcdd5e58b003":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c7e66402a94d4104a7318f77c8f77d96","IPY_MODEL_b8a9f2b21b784d4c8ace83f6f20ae813","IPY_MODEL_8d716ac39f8747cca4b9172d4058ae40"],"layout":"IPY_MODEL_314ae781516a434fa3e20630afe676c8"}},"c7e66402a94d4104a7318f77c8f77d96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b72d083672e4431a4d8427da4fb1757","placeholder":"​","style":"IPY_MODEL_6f068bf59d5d4f34b0031971a81cf2b7","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"b8a9f2b21b784d4c8ace83f6f20ae813":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d579235013284c679fa09bdd15332ba4","max":995526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b44e49dc36ab4c0f9b1a7965b3d37e77","value":995526}},"8d716ac39f8747cca4b9172d4058ae40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_409a5c7cd7dc4d228d5de8da11b546da","placeholder":"​","style":"IPY_MODEL_a2e5d32460ef4517bc8d965593e3999b","value":" 996k/996k [00:00&lt;00:00, 9.69MB/s]"}},"314ae781516a434fa3e20630afe676c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b72d083672e4431a4d8427da4fb1757":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f068bf59d5d4f34b0031971a81cf2b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d579235013284c679fa09bdd15332ba4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b44e49dc36ab4c0f9b1a7965b3d37e77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"409a5c7cd7dc4d228d5de8da11b546da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2e5d32460ef4517bc8d965593e3999b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c908c84ac6a04304b01c45d2731d751a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_896edcfa135e4b688a4a556141761d20","IPY_MODEL_960efdaf19d44b34bdfc1f491480c9cc","IPY_MODEL_524c27d5e0d84eb3a71280e9044d8276"],"layout":"IPY_MODEL_e5b5102d12c1400387d71e32332676e9"}},"896edcfa135e4b688a4a556141761d20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5300f01ba23f455db32eada0b6f9a8bd","placeholder":"​","style":"IPY_MODEL_8ff2f07abe62441cab183cb804f99fe3","value":"Downloading (…)okenizer_config.json: 100%"}},"960efdaf19d44b34bdfc1f491480c9cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_11207315c0dc48c4afe3b680b51578a8","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0bbdb7af03fb415fa01e5b621209b60f","value":29}},"524c27d5e0d84eb3a71280e9044d8276":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4544319004434ce084672c24407c358a","placeholder":"​","style":"IPY_MODEL_80d83f2ae8ed4d02af0f47a8d6222f47","value":" 29.0/29.0 [00:00&lt;00:00, 1.36kB/s]"}},"e5b5102d12c1400387d71e32332676e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5300f01ba23f455db32eada0b6f9a8bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ff2f07abe62441cab183cb804f99fe3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11207315c0dc48c4afe3b680b51578a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bbdb7af03fb415fa01e5b621209b60f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4544319004434ce084672c24407c358a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80d83f2ae8ed4d02af0f47a8d6222f47":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"094affce43c1468583ad2db010528d18":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb47ebcfc0c9410fb2a3e9b23ef2e3d1","IPY_MODEL_c5d3a1f921364c9b882f3cd22ff949dc","IPY_MODEL_e5a192af4e6445a485e9b2dd3647759a"],"layout":"IPY_MODEL_29b7868635d5408bb807c247f31a13dd"}},"cb47ebcfc0c9410fb2a3e9b23ef2e3d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_687475143f01493182e917a88ba3d857","placeholder":"​","style":"IPY_MODEL_bbae3ed57b9c4693b2467e17b62dcd2f","value":"Downloading (…)lve/main/config.json: 100%"}},"c5d3a1f921364c9b882f3cd22ff949dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6ad9dd7e0b545e1b8104b318a255d0a","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_399879f292f24e828ce5a6265db47a71","value":625}},"e5a192af4e6445a485e9b2dd3647759a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dda21360cc6642a7a50701275ae18e97","placeholder":"​","style":"IPY_MODEL_254e736fc7f7472ab0bfd4fb84c846fa","value":" 625/625 [00:00&lt;00:00, 9.34kB/s]"}},"29b7868635d5408bb807c247f31a13dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"687475143f01493182e917a88ba3d857":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbae3ed57b9c4693b2467e17b62dcd2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6ad9dd7e0b545e1b8104b318a255d0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"399879f292f24e828ce5a6265db47a71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dda21360cc6642a7a50701275ae18e97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"254e736fc7f7472ab0bfd4fb84c846fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57a1f4ef9ced4a52bca0a34d876d38a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3cbe220f906340b0a969828e537770a6","IPY_MODEL_92b9f956e7664c52bc79826c7aae4a29","IPY_MODEL_7e6462bd0a974396adf7c650c6ceb870"],"layout":"IPY_MODEL_07649f5e2a804c2fa71408736484dc45"}},"3cbe220f906340b0a969828e537770a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba2478699f574349a9f66dcba210eecb","placeholder":"​","style":"IPY_MODEL_1166a54d74ea4fea8dd0f4199ac2d0af","value":"Downloading model.safetensors: 100%"}},"92b9f956e7664c52bc79826c7aae4a29":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e23808f1bf4c4558a289e0ce9225ee5c","max":714290682,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa9868d2e8cf4fc5bf670be44913806a","value":714290682}},"7e6462bd0a974396adf7c650c6ceb870":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa21852b505d4481a6a67300da47a275","placeholder":"​","style":"IPY_MODEL_3b90a4547c8249a4ac252f9bad409ca5","value":" 714M/714M [00:07&lt;00:00, 103MB/s]"}},"07649f5e2a804c2fa71408736484dc45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba2478699f574349a9f66dcba210eecb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1166a54d74ea4fea8dd0f4199ac2d0af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e23808f1bf4c4558a289e0ce9225ee5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa9868d2e8cf4fc5bf670be44913806a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa21852b505d4481a6a67300da47a275":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b90a4547c8249a4ac252f9bad409ca5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}